{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3cc989",
   "metadata": {},
   "source": [
    "## IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40c46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297708c8",
   "metadata": {},
   "source": [
    "**vocab_size** refers to a vocabulary of 50,257 words, as used by the BPE tokenizer (see chapter 2).\n",
    "\n",
    "**context_length** denotes the maximum number of input tokens the model can handle via the positional embeddings (see chapter 2).\n",
    "\n",
    "**emb_dim** represents the embedding size, transforming each token into a 768 dimensional vector.\n",
    "\n",
    "**n_heads** indicates the count of attention heads in the multi-head attention mechanism (see chapter 3).\n",
    "\n",
    "**n_layers** specifies the number of transformer blocks in the model, which we will cover in the upcoming discussion.\n",
    "\n",
    "**drop_rate** indicates the intensity of the dropout mechanism (0.1 implies a 10%\n",
    "ndom drop out of hidden units) to prevent overfitting (see chapter 3).\n",
    "\n",
    "**qkv_bias** determines whether to include a bias vector in the Linear layers of the multi-head attention for query, key, and value computations. We will initially disable this, following the norms of modern LLMs, but we will revisit it in chapter 6 when we load pretrained GPT-2 weights from OpenAI into our model (see chapter 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0fb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc83b6",
   "metadata": {},
   "source": [
    "### STEP 1: TOKENIZATION    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cac62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch,dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b961e33",
   "metadata": {},
   "source": [
    "### STEP 2: CREATE AN INSTANCE OF DUMMYGPTMODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee34cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b81709",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 2: LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5518a8",
   "metadata": {},
   "source": [
    "#### Explanation with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08414564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91dbc358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44de788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm= (out - mean)/torch.sqrt(var)\n",
    "mean = out_norm.mean(dim= -1, keepdim=True)\n",
    "var = out_norm.var(dim= -1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd148cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0996adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps= 1e-5\n",
    "        self.sacle= nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift= nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        vars = x.var(dim=-1,keepdim=True , correction=False)\n",
    "        norm_x = (x- mean)/torch.sqrt(vars+self.eps)\n",
    "        return self.sacle*norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd246028",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed71d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34a975",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1ef93",
   "metadata": {},
   "source": [
    "- GELU ([Hendrycks and Gimpel 2016](https://arxiv.org/abs/1606.08415)) can be implemented in several ways; the exact version is defined as GELU(x)=x⋅Φ(x), where Φ(x) is the cumulative distribution function of the standard Gaussian distribution.\n",
    "- In practice, it's common to implement a computationally cheaper approximation: $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
    "$ (the original GPT-2 model was also trained with this approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50137515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6df281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8caa93c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013ac39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768) \n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064473a",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/10.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd425dca",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265a96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])  \n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8311b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]  \n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff6adee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c97d94",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "82d46a54",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147bf2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa55d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Attention import MultiHeadAttention\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d99560af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a021f",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f90caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e06a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87eb8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2517c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "040c509e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb7ffc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105d065",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f2ad37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd6c7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95e6d72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdc460b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
